{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DESCARGA DE DATOS DE INCIDENCIA DELICTIVA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHx2_ZGJQiKZ",
        "outputId": "7f72f161-4544-4991-e3ba-802176c0c287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
            "Requirement already satisfied: requests in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: gdown in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->gdown) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: html5lib in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1)\n",
            "Requirement already satisfied: six>=1.9 in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from html5lib) (1.16.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from html5lib) (0.5.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalando las paqueterías necesarias.\n",
        "%pip install pandas openpyxl requests beautifulsoup4\n",
        "%pip install wget\n",
        "%pip install gdown\n",
        "%pip install unidecode\n",
        "%pip install lxml\n",
        "%pip install html5lib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlT8D8oM1f2p"
      },
      "source": [
        "Las siguientes librerías nos ayudaran para el desarrollo del proceso de descarga y generación del archivo txt. es necesario que este al principio para su correcto funcionamiento.\n",
        "\n",
        "Se utiliza librerías especiales como gwdown para descarga de archivos grandes, eliminando la confirmación de permiso de descarga.\n",
        "\n",
        "Se utiliza librería unicode, para poder quitar los acentos de ciertas palabras y usarlo como nombre de archivos a descargar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gY6pHKnxVf02"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías para usarlas en el proyecto de descarga y generación del txt con la descripción de esta\n",
        "import pandas as pd\n",
        "import wget\n",
        "import gdown\n",
        "import requests\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import lxml\n",
        "import html5lib\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from logging import exception\n",
        "from unidecode import unidecode\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrKBE0zm2OZK"
      },
      "source": [
        "La inicialización de ciertas variables ayudaran a preparar la información inicial de cada una de ellas, además de que puedan ser usadas en cualquier parte del código o proceso, sin en el que perjudique el ámbito o espacio donde estas estén siendo seteadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "vB3CEL3HoRBp"
      },
      "outputs": [],
      "source": [
        "# Inicializando variables que serán usadas más adelante\n",
        "\n",
        "incidencia_delictiva_link = 'https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva'\n",
        "incidencia_title = ''\n",
        "incidencia_description = ''\n",
        "\n",
        "folder_path_data = '../rawdata'\n",
        "folder_path_log = '../logs/descarga/'\n",
        "folder_path_error_log = '../logs/errores/'\n",
        "csv_filepath = ''\n",
        "\n",
        "# Creando variable que contendra el listado de cada source descargado.\n",
        "sources_list = []\n",
        "\n",
        "# Creando variable que contendra el listado de cada nombre de archivo descargado y que esta siendo enviado a nuestro repositorio\n",
        "names_files_list = []\n",
        "\n",
        "texto_list = ''\n",
        "\n",
        "serie_mujeres_region = []\n",
        "serie_mujeres_indicador = []\n",
        "\n",
        "# Obténiendo el año actual\n",
        "actual_year = datetime.now().year\n",
        "\n",
        "# Creando la serie de años para usarlo en descargas que se ocupa el dinamismo de años\n",
        "years_serie = pd.Series(range(2013, actual_year + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sección donde se encuentran las funciones generales del proceso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_error_write(description, line):\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_error_log):\n",
        "        os.makedirs(folder_path_error_log)\n",
        "        \n",
        "    date_now = datetime.now()\n",
        "\n",
        "    # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "    line_error = f\"\"\"{date_now.strftime('%Y-%m-%d %H:%M:%S')} {line} - {description}\"\"\"\n",
        "    # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "    with open(f'{folder_path_error_log}/ddf_err{date_now.strftime(\"%d%m%y\")}.txt', 'a', encoding=\"utf-8\") as error_file:\n",
        "        error_file.write(f\"\\n{line_error}\")\n",
        "\n",
        "def log_write(description, line):\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_log):\n",
        "        os.makedirs(folder_path_log)\n",
        "        \n",
        "    date_now = datetime.now()\n",
        "\n",
        "    # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "    line_write = f\"\"\"{date_now.strftime('%Y-%m-%d %H:%M:%S')} {line} - {description}\"\"\"\n",
        "    # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "    with open(f'{folder_path_log}/muncoord{date_now.strftime(\"%d%m%y\")}.txt', 'a', encoding=\"utf-8\") as write_file:\n",
        "        write_file.write(f\"\\n{line_write}\")\n",
        "\n",
        "def create_csv_from_DataFrame(df, csv_filename):\n",
        "    try:\n",
        "\n",
        "        # Construyendo la ruta completa del archivo\n",
        "        csv_filepath = os.path.join(folder_path_data, csv_filename)\n",
        "\n",
        "        # Guardando el DataFrame como un archivo CSV\n",
        "        df.to_csv(csv_filepath, index=False, encoding='utf-8')\n",
        "        print(f\"DataFrame guardado exitosamente en {csv_filepath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Imprimiendo un mensaje de error en caso de excepción\n",
        "        log_error_write(f\"Error al guardar el DataFrame como CSV: {e}\", 'create_csv_from_DataFrame')\n",
        "        print(f\"Error al guardar el DataFrame como CSV: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sección donde se encuentran las funciones para los distintos metodos de descarga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "elWoM2gu1znm"
      },
      "outputs": [],
      "source": [
        "# sección de funciones para descarga de archivos desde fuentes que vienen de enlaces proporcionados por la página del gobierno.\n",
        "\n",
        "# Función utilizada para la descarga de archivos almacenados en google drive por parte de la institución donde se requiere obtener los datos.\n",
        "# - document: recibe el id del documento en google drive.\n",
        "# - description: Texto de la etiqueta de enlace, el cual describe la naturaleza de la información a descargar.\n",
        "def download_csv_from_http(document, description):\n",
        "\n",
        "  print(f\"link \" + description)\n",
        "\n",
        "  try:\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_data):\n",
        "        os.makedirs(folder_path_data)\n",
        "\n",
        "    # Url de descarga a traves de google drive\n",
        "    csv_url = f'https://drive.google.com/uc?id={document}'\n",
        "\n",
        "    # Descargando archivos desde la url proporcionada\n",
        "    response_csv = requests.get(csv_url)\n",
        "\n",
        "    # Parte donde se hace una limpieza del parámetro description enviado,\n",
        "    # esto para construir el nombre que tendrá el archivo csv que se descarga a partir de los datos de las fuentes\n",
        "    # Utilizando expresión regular para reemplazar caracteres especiales y espacios por un solo guion bajo aplicándolo en la descripción del enlace.\n",
        "    csv_filename = re.sub(r'[^\\w\\s]+', '', description)\n",
        "    csv_filename = re.sub(r'\\s+', '', csv_filename)\n",
        "    # Utilizando unidecode para quitar los acentos y no cause conflictos como nombre de archivo\n",
        "    csv_filename = unidecode(csv_filename)\n",
        "    csv_filename = csv_filename + \".csv\"\n",
        "\n",
        "    # Construyendo la ruta completa del archivo\n",
        "    csv_filepath = os.path.join(folder_path_data, csv_filename)\n",
        "\n",
        "    names_files_list.append(csv_filename)\n",
        "    #------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Guardando el archivo descargado, en el repositorio del proyecto\n",
        "    with open(csv_filepath, 'wb') as csv_file:\n",
        "      csv_file.write(response_csv.content)\n",
        "\n",
        "    # Leer el archivo CSV con la codificación original\n",
        "    df = pd.read_csv(csv_filepath, encoding='latin1')\n",
        "\n",
        "    # Guardar el archivo CSV con codificación UTF-8\n",
        "    df.to_csv(csv_filepath, index=False, encoding='utf-8')\n",
        "  \n",
        "  except ValueError as ve:\n",
        "    # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "    log_error_write(f\"Error de valor: {ve}\", 'download_csv_from_http')\n",
        "    print(f\"Error de valor: {ve}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "    log_error_write(f\"Ocurrió un error inesperado: {e}\", 'download_csv_from_http')\n",
        "    print(f\"Ocurrió un error inesperado: {e}\")\n",
        "\n",
        "  else:\n",
        "    # Este bloque se ejecuta si no se produce ninguna excepción en el bloque try\n",
        "    print(\"¡Proceso download_csv_from_http de descarga completado!\")\n",
        "\n",
        "  finally:\n",
        "    # Este bloque siempre se ejecuta, independientemente de si se produjo una excepción o no\n",
        "    print(\"¡Fin de la descarga!\")\n",
        "\n",
        "# *****************************************************************************************************************************************\n",
        "\n",
        "# Función utilizada para la descarga de archivos almacenados en google drive por parte de la institución donde se requiere obtener los datos.\n",
        "# - document: recibe el id del documento en google drive.\n",
        "# - description: Texto de la etiqueta de enlace, el cual describe la naturaleza de la información a descargar.\n",
        "# (Para descarga de documentos muy grandes, libreria gdown)\n",
        "def download_csv_from_http_high(document, description):\n",
        "\n",
        "  print(f\"link \" + description)\n",
        "\n",
        "  try:\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_data):\n",
        "      os.makedirs(folder_path_data)\n",
        "\n",
        "    # Url de descarga a traves de google drive\n",
        "    csv_url = f'https://drive.google.com/uc?id={document}'\n",
        "\n",
        "    # Parte donde se hace una limpieza del parámetro description enviado,\n",
        "    # esto para construir el nombre que tendrá el archivo csv que se descarga a partir de los datos de las fuentes\n",
        "    # Utilizando expresión regular para reemplazar caracteres especiales y espacios por un solo guion bajo aplicándolo en la descripción del enlace.\n",
        "    csv_filename = re.sub(r'[^\\w\\s]+', '', description)\n",
        "    csv_filename = re.sub(r'\\s+', '', csv_filename)\n",
        "    csv_filename = unidecode(csv_filename)\n",
        "    csv_filename = csv_filename + \".csv\"\n",
        "\n",
        "    # Construyendo la ruta completa del archivo\n",
        "    csv_filepath = os.path.join(folder_path_data, csv_filename)\n",
        "\n",
        "    names_files_list.append(csv_filename)\n",
        "    #----------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Utilizando wget para descargar archivos grandes sin restricciones\n",
        "    gdown.download(csv_url, csv_filepath, quiet=False)\n",
        "\n",
        "    # Leer el archivo CSV con la codificación original\n",
        "    df = pd.read_csv(csv_filepath, encoding='latin1')\n",
        "\n",
        "    # Guardar el archivo CSV con codificación UTF-8\n",
        "    df.to_csv(csv_filepath, index=False, encoding='utf-8')\n",
        "  \n",
        "  except ValueError as ve:\n",
        "    # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "    log_error_write(f\"Error de valor: {ve}\", 'download_csv_from_http_high')\n",
        "    print(f\"Error de valor: {ve}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "    log_error_write(f\"Ocurrió un error inesperado: {e}\", 'download_csv_from_http_high')\n",
        "    print(f\"Ocurrió un error inesperado: {e}\")\n",
        "\n",
        "  else:\n",
        "    # Este bloque se ejecuta si no se produce ninguna excepción en el bloque try\n",
        "    print(\"¡Proceso download_csv_from_http_high de descarga completado!\")\n",
        "\n",
        "  finally:\n",
        "    # Este bloque siempre se ejecuta, independientemente de si se produjo una excepción o no\n",
        "    print(\"¡Fin de la descarga!\")\n",
        "\n",
        "# *******************************************************************************************************************************************************************\n",
        "\n",
        "\n",
        "def download_from_api_high(api_url, parameters):\n",
        "    try:\n",
        "        # Realizando la solicitud GET a la API con los parámetros\n",
        "        response = requests.get(api_url, params=parameters)\n",
        "\n",
        "        # Verificando si la solicitud fue exitosa (código 200)\n",
        "        if response.status_code == 200:\n",
        "            # Convertir la respuesta JSON en un DataFrame de pandas\n",
        "            df = pd.DataFrame(response.json())\n",
        "\n",
        "            return df\n",
        "\n",
        "        else:\n",
        "            # Imprimir un mensaje de error si la solicitud no fue exitosa\n",
        "            log_error_write(f\"Error al realizar la solicitud. Código de estado: {response.status_code}\", 'download_from_api')\n",
        "            print(f\"Error al realizar la solicitud. Código de estado: {response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Imprimir un mensaje de error en caso de excepción\n",
        "        log_error_write(f\"Ocurrió un error inesperado: {e}\", 'download_from_api')\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# *******************************************************************************************************************************************************************\n",
        "\n",
        "def download_from_get_request_json(url, parameters, object_request,columns, name_file):\n",
        "  \n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  \n",
        "  try:\n",
        "    #Se construye la url con los parametros proporcionados\n",
        "    url = url + '?' + parameters\n",
        "\n",
        "    # Realizando la solicitud GET para descargar los datos\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Comprobando si la solicitud fue exitosa\n",
        "    if response.status_code == 200:\n",
        "        # Leeyendo el contenido de la respuesta en un DataFrame\n",
        "        df_response = pd.DataFrame(response.json())\n",
        "\n",
        "        # Accediendo a la parte 'aaData' del JSON\n",
        "        aaData_series = df_response[object_request]\n",
        "\n",
        "        #Se llena el dataframe con cada serie que contiene uno de los objetos de la respuesta de la petición.\n",
        "        for a in aaData_series:\n",
        "           df.loc[len(df)] = a\n",
        "               \n",
        "    else:\n",
        "        log_error_write(f\"Ocurrió un error inesperado: {response.reason}\", 'Obteniendo datos {url}')\n",
        "        print(f\"Ocurrió un error inesperado: {response.reason}\")\n",
        "\n",
        "  except ValueError as ve:\n",
        "    # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "    log_error_write(f\"Error de valor: {ve}\", 'Obteniendo datos {url}')\n",
        "    print(f\"Error de valor: {ve}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "    log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Obteniendo datos {url}')\n",
        "    print(f\"Ocurrió un error inesperado: {e}\")\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Web Scraping para obtener las regiones geograficas en las que esta divido el estado de Sonora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Municipio         Region\n",
            "0                   Altar       Noraeste\n",
            "1                    Átil       Noraeste\n",
            "2                 Caborca       Noraeste\n",
            "3                 Oquitoa       Noraeste\n",
            "4               Pitiquito       Noraeste\n",
            "..                    ...            ...\n",
            "67             San Javier  Sierra Centro\n",
            "68  San Pedro de la Cueva  Sierra Centro\n",
            "69                 Soyopa  Sierra Centro\n",
            "70          Suaqui Grande  Sierra Centro\n",
            "71        Villa Pesqueira  Sierra Centro\n",
            "\n",
            "[72 rows x 2 columns]\n",
            "DataFrame guardado exitosamente en ../rawdata\\municipios_regiones.csv\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  \n",
        "  url = f'https://contraloria.sonora.gob.mx/component/zoo/category/regiones.html'\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  pretty_soup = soup.prettify()\n",
        "\n",
        "  # Inicializando listas para las columnas del DataFrame\n",
        "  municipios = []\n",
        "  regiones = []\n",
        "\n",
        "  # Se encuentra todas las etiquetas h2 que contienen nombres de regiones\n",
        "  for h2_region in soup.find_all('h2', {'class': 'title'}):\n",
        "      # Se extrae el nombre de la región\n",
        "      nombre_region = h2_region.find('a').text.strip()\n",
        "\n",
        "      # Se encuentra la siguiente etiqueta ul (lista) después del h2\n",
        "      ul_lista = h2_region.find_next('ul', {'class': 'sub-categories'})\n",
        "      \n",
        "      # Iterando sobre cada li (elemento de la lista) dentro de la ul\n",
        "      for li_ciudad in ul_lista.find_all('li'):\n",
        "          # Extrayendo el nombre del municipio\n",
        "          nombre_municipio = li_ciudad.find('a').text.strip()\n",
        "          \n",
        "          # Agregando el nombre del municipio y de la región a las listas\n",
        "          municipios.append(nombre_municipio)\n",
        "          regiones.append(nombre_region)\n",
        "\n",
        "  # Creando el DataFrame\n",
        "  regiones_df = pd.DataFrame({'Municipio': municipios, 'Region': regiones})\n",
        "\n",
        "  # Muestra el DataFrame resultante\n",
        "  print(regiones_df)\n",
        "\n",
        "  create_csv_from_DataFrame(regiones_df, f\"municipios_regiones.csv\")\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'web scraping regiones')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'web scraping regiones')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Web Scraping para obtener las coordenadas geográficas de todos los municipios de Sonora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame guardado exitosamente en ../rawdata\\municipios_coordenadas.csv\n",
            "        municipio   latitude   longitude\n",
            "0         Aconchi  29.825040 -110.227170\n",
            "1     Agua-Prieta  30.948490 -109.274370\n",
            "2          Alamos  27.026940 -108.936590\n",
            "3           Altar  30.713610 -111.835280\n",
            "4        Arivechi  28.927990 -109.188300\n",
            "..            ...        ...         ...\n",
            "67          Rayón  29.710556 -110.570278\n",
            "68        Rosario  28.050000 -109.300000\n",
            "69      Santa Ana  30.543889 -111.121111\n",
            "70  Villa Hidalgo  30.250000 -109.333333\n",
            "71  Benito Juárez  27.100000 -109.850000\n",
            "\n",
            "[72 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Inicializando listas para almacenar los datos\n",
        "ciudades = []\n",
        "latitudes = []\n",
        "longitudes = []\n",
        "\n",
        "try:\n",
        "  \n",
        "  for num in range(2):\n",
        "    url = f'https://www.coordenadas.com.es/mexico/pueblos-de-sonora/26/{num + 1}'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    pretty_soup = soup.prettify()\n",
        "\n",
        "  # Encontrando el elemento tabla desde el html obtenido\n",
        "    tabla = soup.find('table', class_='table')\n",
        "\n",
        "    # Iterarando sobre las filas de la tabla\n",
        "    for fila in tabla.find_all('tr'):\n",
        "        # buscando y encontrando las celdas de la fila\n",
        "        celdas = fila.find_all('td')\n",
        "        \n",
        "        # Verificando si hay celdas (evitando encabezados de la tabla)\n",
        "        if celdas:\n",
        "            # Extrayendo el texto de la etiqueta <a> dentro de la primera celda\n",
        "            ciudad = celdas[0].find('a').text.strip()\n",
        "            # Extrayendo el texto de la segunda celda\n",
        "            coordenada = celdas[1].text.strip()\n",
        "            \n",
        "            # Dividiendo las coordenadas en latitude y longitude\n",
        "            latitud, longitud = map(float, coordenada.split(','))\n",
        "            \n",
        "            ciudades.append(ciudad)\n",
        "            latitudes.append(latitud)\n",
        "            longitudes.append(longitud)\n",
        "\n",
        "  coordenadas_df = pd.DataFrame({\n",
        "     'municipio': ciudades,\n",
        "     'latitude': latitudes,\n",
        "     'longitude': longitudes\n",
        "     })\n",
        "  \n",
        "\n",
        "  #llenando la informacion faltante\n",
        "\n",
        "  Mmunicipios_left_df = pd.DataFrame({\n",
        "     'municipio': [\"Magdalena\", \"Mazatán\", \"Moctezuma\", \"Rayón\", \"Rosario\", \"Santa Ana\", \"Villa Hidalgo\", \"Benito Juárez\"],\n",
        "     'latitude': [30.733333, 28.933333, 29.806111, 29.710556, 28.05, 30.543889, 30.25, 27.1],\n",
        "     'longitude': [-111.05, -110.166667, -109.679444, -110.570278, -109.3, -111.121111, -109.333333,  -109.85]\n",
        "  })\n",
        "\n",
        "  coordenadas_df = pd.concat([coordenadas_df,Mmunicipios_left_df], ignore_index = True)\n",
        "\n",
        "  create_csv_from_DataFrame(coordenadas_df, f'municipios_coordenadas.csv')\n",
        "\n",
        "  # Mostrar el DataFrame resultante\n",
        "  print(coordenadas_df)\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'web scraping coordenadas')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'web scraping coordenadas')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Web Scraping , proceso de descarga de los datos de incidencia delicitva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gsk95W9Y_U6",
        "outputId": "dc72757f-acc8-4e01-f291-c331f9a0ae2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Descargando archivos proporcionados por https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva\n",
            "link Cifras de Incidencia Delictiva Estatal, 2015 - septiembre  2023\n",
            "¡Proceso download_csv_from_http de descarga completado!\n",
            "¡Fin de la descarga!\n",
            "link Cifras de Incidencia Delictiva Municipal, 2015 - septiembre 2023. \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1r_D3qmptB6uuUJoVKEHfsDDdkp6HRRPz\n",
            "From (redirected): https://drive.google.com/uc?id=1r_D3qmptB6uuUJoVKEHfsDDdkp6HRRPz&confirm=t&uuid=f899d69e-d355-4faa-975f-9159ab68b508\n",
            "To: c:\\Proyectos\\Maestria\\IngenieriaCaracteristicas\\Proyectos\\IC-Proyecto-Indicadores-Delictivos\\rawdata\\CifrasdeIncidenciaDelictivaMunicipal2015septiembre2023.csv\n",
            "100%|██████████| 306M/306M [00:35<00:00, 8.58MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Proceso download_csv_from_http_high de descarga completado!\n",
            "¡Fin de la descarga!\n",
            "Cifras de Incidencia Delictiva Municipal, 2015 - septiembre 2023. : https://drive.google.com/file/d/1r_D3qmptB6uuUJoVKEHfsDDdkp6HRRPz/view?usp=sharing\n",
            "link Cifras de Víctimas del Fuero Común, 2015 - septiembre 2023\n",
            "¡Proceso download_csv_from_http de descarga completado!\n",
            "¡Fin de la descarga!\n",
            "link Cifras de Incidencia Delictiva Federal, 2012 - septiembre 2023\n",
            "¡Proceso download_csv_from_http de descarga completado!\n",
            "¡Fin de la descarga!\n"
          ]
        }
      ],
      "source": [
        "# Descargando archivos proporcionados por https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva\n",
        "print('# Descargando archivos proporcionados por https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva')\n",
        "# Realizando Web scraping a la página donde están las distintas fuentes de datos\n",
        "# Esto asegura que los datos puedan ser descargados de forma automática sin necesidad de estar descargado uno por uno directamente desde la página.\n",
        "url = 'https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva'\n",
        "\n",
        "try:\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  pretty_soup = soup.prettify()\n",
        "\n",
        "  # Obteniendo el texto dentro de la etiqueta <title>\n",
        "  incidencia_source_title = soup.title.text.strip()\n",
        "\n",
        "  # Separando el texto por los pipes \"|\", esto porque el texto original viene con dicho carácter especial\n",
        "  title_parts = incidencia_source_title.split('|')\n",
        "\n",
        "  # Limpiando los espacios en blanco alrededor de cada parte del titulo encontrado\n",
        "  title_parts = [part.strip() for part in title_parts]\n",
        "\n",
        "  incidencia_title = title_parts[0] + \" - \" + title_parts[1]\n",
        "\n",
        "  # Buscando todas las etiquetas <h2> y extraer su texto, esto ayudara a poder extraer la descripción de la página, la explicación de la razón de la página.\n",
        "  h2_tags = soup.find_all('h2')\n",
        "\n",
        "  # Se recorren cada una de los parrafos H2 encontrados para luego extraer el texto en donde comience con \"En esta pagina...\".\n",
        "  for h2_tag in h2_tags:\n",
        "      text_inside_h2 = h2_tag.text.strip()\n",
        "\n",
        "      if(text_inside_h2.find('En esta página')!=-1) :\n",
        "        incidencia_description = text_inside_h2\n",
        "\n",
        "  # Buscando todas las etiquetas <ul>, esto ayudara más adelante a poder realizar las descargas, pues aquí se encontrará las url de cada enlace.\n",
        "  ul_tags = soup.find_all('ul')\n",
        "\n",
        "  for ul_tag in ul_tags:\n",
        "      # Buscando todas las etiquetas <li> dentro de cada <ul>\n",
        "      li_tags = ul_tag.find_all('li')\n",
        "\n",
        "      for li_tag in li_tags:\n",
        "          # Buscando todas las etiquetas <a> dentro de cada <li> con texto que comienza con \"Cifras\"\n",
        "          a_tags = li_tag.find_all('a', href=True, string=lambda x: x and x.startswith('Cifras'))\n",
        "\n",
        "          for a_tag in a_tags:\n",
        "              # Obteniendo el valor del atributo href, para extraer su url\n",
        "              href_value = a_tag['href']\n",
        "\n",
        "              # Utilizando expresión regular para extraer la parte antes de \"/view\" de cada url esto para conseguir el id del documento\n",
        "              match = re.search(r'/file/d/(.*?)/view', href_value)\n",
        "              # match = re.search(r'(.*?)/view', href_value)\n",
        "\n",
        "              # En caso de encontrar coicidencia, se procede a extraer el id del documento de descarga.\n",
        "              if match:\n",
        "                extracted_part = match.group(1)\n",
        "                if a_tag.text.find(str(datetime.now().year)) != -1:\n",
        "                  # Condicionante para poder detectar si la descarga es de datos referentes a municipios, esto por conocimiento, son descargas más pesadas y por lo cual se ocupa de librería especial.\n",
        "                  if a_tag.text.find('Municipal') != -1:\n",
        "                    download_csv_from_http_high(extracted_part, a_tag.text)\n",
        "\n",
        "                    # Imprimiendo el tag descriptivo y la url para mostrarla en pantalla\n",
        "                    print(f\"\"+ a_tag.text + \": \" + href_value)\n",
        "                  else:\n",
        "                    download_csv_from_http(extracted_part, a_tag.text)\n",
        "\n",
        "                  #Creando listado que será usado para el documento con la descripción de la descarga de las distintas fuentes, de incidencia delictiva\n",
        "                  sources_list.append(f\"- {a_tag.text}: {href_value}\")\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'web scraping')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'web scraping')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GET Request , proceso de descarga de los datos de incidencia delicitva cometido contra las mujeres (Por tipo de delito o indicador)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame guardado exitosamente en ../rawdata\\CifrasIncidenciaDelictivaContraMujeresIndicador.csv\n",
            "                     Tipo de delito Enero Febrero Marzo Abril Mayo Junio  \\\n",
            "0                Violencia Familiar   167     168   169   163  178   164   \n",
            "1                       Negligencia    25      30    21    43   26    36   \n",
            "2                      Abuso Físico    26      19    19    45   30    28   \n",
            "3  Incumpl. obligaciones familiares    31      26    21    22   28    34   \n",
            "4               Omisión de Cuidados    15       4     7    19   12    12   \n",
            "\n",
            "  Julio Agosto Septiembre Octubre Noviembre Diciembre Total Porcentaje   Año  \n",
            "0   103    156        154     140         0         0  1562     58.9 %  2013  \n",
            "1    25     28         22      13         0         0   269     10.1 %  2013  \n",
            "2    22     33         17      21         0         0   260      9.8 %  2013  \n",
            "3    19     35         20      21         0         0   257      9.7 %  2013  \n",
            "4    11     15          5      14         0         0   114      4.3 %  2013  \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    df_mujeres = pd.DataFrame()\n",
        "\n",
        "    # URL del enlace\n",
        "    url = f\"http://baesvim.sspsonora.gob.mx/Indicadores/ObtDetallesAnualDelito\"\n",
        "    # El nombre de las columnas que va tener el dataframe que se requiere, se considera el numero de columnas que contiene la respuesta de la petición\n",
        "    columns=[\"Tipo de delito\", \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\", \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\", \"Total\", \"Porcentaje\"]\n",
        "    name_file = \"CifrasIncidenciaDelictivaContraMujeresIndicador.csv\"\n",
        "    object_request = \"aaData\"\n",
        "\n",
        "    for year in years_serie:\n",
        "      # Parametros de la petición que necesita para obtener una respuesta correcta, se forma como una cadena string para poder hacerlo dinamico el llamado.\n",
        "      parameters = f\"sEcho=1&iColumns=15&sColumns=municipio%2Cene%2Cfeb%2Cmar%2Cabr%2Cmay%2Cjun%2Cjul%2Cago%2Csep%2Coct%2Cnov%2Cdic%2Ctotal%2Cpromedio&iDisplayStart=0&iDisplayLength=81&mDataProp_0=0&sSearch_0=&bRegex_0=false&bSearchable_0=false&bSortable_0=false&mDataProp_1=1&sSearch_1=&bRegex_1=false&bSearchable_1=false&bSortable_1=true&mDataProp_2=2&sSearch_2=&bRegex_2=false&bSearchable_2=false&bSortable_2=true&mDataProp_3=3&sSearch_3=&bRegex_3=false&bSearchable_3=true&bSortable_3=true&mDataProp_4=4&sSearch_4=&bRegex_4=false&bSearchable_4=true&bSortable_4=true&mDataProp_5=5&sSearch_5=&bRegex_5=false&bSearchable_5=true&bSortable_5=true&mDataProp_6=6&sSearch_6=&bRegex_6=false&bSearchable_6=true&bSortable_6=true&mDataProp_7=7&sSearch_7=&bRegex_7=false&bSearchable_7=true&bSortable_7=true&mDataProp_8=8&sSearch_8=&bRegex_8=false&bSearchable_8=true&bSortable_8=true&mDataProp_9=9&sSearch_9=&bRegex_9=false&bSearchable_9=true&bSortable_9=true&mDataProp_10=10&sSearch_10=&bRegex_10=false&bSearchable_10=true&bSortable_10=true&mDataProp_11=11&sSearch_11=&bRegex_11=false&bSearchable_11=true&bSortable_11=true&mDataProp_12=12&sSearch_12=&bRegex_12=false&bSearchable_12=true&bSortable_12=true&mDataProp_13=13&sSearch_13=&bRegex_13=false&bSearchable_13=true&bSortable_13=true&mDataProp_14=14&sSearch_14=&bRegex_14=false&bSearchable_14=false&bSortable_14=false&sSearch=&bRegex=false&iSortCol_0=13&sSortDir_0=desc&iSortingCols=1&llave_clasificacion=1&id_mpo=0&anio={year}&mes={str(datetime.now().month)}\"\n",
        "      \n",
        "      # Se manda llamar la función que realiza la petición al servicio que manda como respuesta los datos que se necesitan.\n",
        "      df_download = download_from_get_request_json(url, parameters,object_request,columns,name_file)\n",
        "\n",
        "      df_download['Año'] = year\n",
        "\n",
        "      df_mujeres = pd.concat([df_mujeres,df_download], ignore_index = True)\n",
        "\n",
        "    #Creando serie para utilizarla en documento txt\n",
        "    serie_mujeres_indicador = df_mujeres['Tipo de delito'].values\n",
        "  \n",
        "    # Creando el archivo a partir del dataframe creado.\n",
        "    create_csv_from_DataFrame(df_mujeres, name_file)\n",
        "    \n",
        "    print(df_mujeres.head())\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Obteniendo datos baesvim.sspsonora.gob.mx')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Obteniendo datos baesvim.sspsonora.gob.mx')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GET Request , proceso de descarga de los datos de incidencia delicitva cometido contra las mujeres (Por municipio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame guardado exitosamente en ../rawdata\\CifrasIncidenciaDelictivaContraMujeresMunicipio.csv\n",
            "  Clave              Municipio Enero Febrero Marzo Abril Mayo Junio Julio  \\\n",
            "0     0                 SONORA   284     257   256   307  300   290   198   \n",
            "1    30             HERMOSILLO   162     167   146   198  183   174   123   \n",
            "2    43                NOGALES    28      21    25    27   20    21    21   \n",
            "3    18                 CAJEME    25      17    13    21   22    27    12   \n",
            "4    55  SAN LUIS RIO COLORADO    10       8    15    12   12    12     6   \n",
            "\n",
            "  Agosto Septiembre Octubre Noviembre Diciembre Total Porcentaje   Año  \n",
            "0    286        240     231         0         0  2649    100.0 %  2013  \n",
            "1    180        132     137         0         0  1602     60.4 %  2013  \n",
            "2     23         27      15         0         0   228      8.6 %  2013  \n",
            "3     14         15      16         0         0   182      6.8 %  2013  \n",
            "4     14         11      10         0         0   110      4.1 %  2013  \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    df_mujeres_municipio = pd.DataFrame()\n",
        "    # URL del enlace\n",
        "    url = f\"http://baesvim.sspsonora.gob.mx/Indicadores/ObtDetallesAnualRegion\"\n",
        "\n",
        "     # El nombre de las columnas que va tener el dataframe que se requiere, se considera el numero de columnas que contiene la respuesta de la petición\n",
        "    columns=[\"Clave\",\"Municipio\", \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\", \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\", \"Total\", \"Porcentaje\"]\n",
        "    name_file = \"CifrasIncidenciaDelictivaContraMujeresMunicipio.csv\"\n",
        "    object_request = \"aaData\"\n",
        "\n",
        "    for year in years_serie:\n",
        "      # Parametros de la petición que necesita para obtener una respuesta correcta, se forma como una cadena string para poder hacerlo dinamico el llamado.\n",
        "      parameters = f\"sEcho=1&iColumns=16&sColumns=id_mpo%2Cmunicipio%2Cene%2Cfeb%2Cmar%2Cabr%2Cmay%2Cjun%2Cjul%2Cago%2Csep%2Coct%2Cnov%2Cdic%2Ctotal%2Cpromedio&iDisplayStart=0&iDisplayLength=81&mDataProp_0=0&sSearch_0=&bRegex_0=false&bSearchable_0=false&bSortable_0=false&mDataProp_1=1&sSearch_1=&bRegex_1=false&bSearchable_1=false&bSortable_1=false&mDataProp_2=2&sSearch_2=&bRegex_2=false&bSearchable_2=false&bSortable_2=true&mDataProp_3=3&sSearch_3=&bRegex_3=false&bSearchable_3=false&bSortable_3=true&mDataProp_4=4&sSearch_4=&bRegex_4=false&bSearchable_4=true&bSortable_4=true&mDataProp_5=5&sSearch_5=&bRegex_5=false&bSearchable_5=true&bSortable_5=true&mDataProp_6=6&sSearch_6=&bRegex_6=false&bSearchable_6=true&bSortable_6=true&mDataProp_7=7&sSearch_7=&bRegex_7=false&bSearchable_7=true&bSortable_7=true&mDataProp_8=8&sSearch_8=&bRegex_8=false&bSearchable_8=true&bSortable_8=true&mDataProp_9=9&sSearch_9=&bRegex_9=false&bSearchable_9=true&bSortable_9=true&mDataProp_10=10&sSearch_10=&bRegex_10=false&bSearchable_10=true&bSortable_10=true&mDataProp_11=11&sSearch_11=&bRegex_11=false&bSearchable_11=true&bSortable_11=true&mDataProp_12=12&sSearch_12=&bRegex_12=false&bSearchable_12=true&bSortable_12=true&mDataProp_13=13&sSearch_13=&bRegex_13=false&bSearchable_13=true&bSortable_13=true&mDataProp_14=14&sSearch_14=&bRegex_14=false&bSearchable_14=true&bSortable_14=true&mDataProp_15=15&sSearch_15=&bRegex_15=false&bSearchable_15=false&bSortable_15=false&sSearch=&bRegex=false&iSortCol_0=14&sSortDir_0=desc&iSortingCols=1&llave_clasificacion=1&id_mpo=0&anio={year}&mes={str(datetime.now().month)}\"\n",
        "     \n",
        "      # Se manda llamar la función que realiza la petición al servicio que manda como respuesta los datos que se necesitan.\n",
        "      df_download = download_from_get_request_json(url, parameters,object_request,columns,name_file)\n",
        "\n",
        "      df_download['Año'] = year\n",
        "\n",
        "      df_mujeres_municipio = pd.concat([df_mujeres_municipio,df_download], ignore_index = True)\n",
        "\n",
        "    #Creando serie para utilizarla en documento txt\n",
        "    serie_mujeres_region = df_mujeres_municipio['Municipio'].values\n",
        "  \n",
        "    # Creando el archivo a partir del dataframe creado.\n",
        "    create_csv_from_DataFrame(df_mujeres_municipio, name_file)\n",
        "    \n",
        "    print(df_mujeres_municipio.head())\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Obteniendo datos baesvim.sspsonora.gob.mx')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Obteniendo datos baesvim.sspsonora.gob.mx')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sección donde se crea el dataset que contiene los nombres de los diferentes archivos descargados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_--TzngMSZL7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    \n",
        "    # Convertiendo la lista de nombres de archivos generados a DataFrame\n",
        "    df_names = pd.DataFrame(names_files_list)\n",
        "\n",
        "    df_names = df_names.rename(columns={0: \"nombre\"})\n",
        "\n",
        "    # Guardando el DataFrame como un archivo CSV\n",
        "    df_names.to_csv(f'{folder_path_data}/nombres_dataset.csv', index=False, encoding='utf-8')\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Creación de dataset de nombres')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Creación de dataset de nombres')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sección para dar validación de la cantidad de archivos descargados referente a incidencia delectiva, el numero esperado a la fecha es de 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Todo en orden, en la generación de los distintos archivos\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "\n",
        "  nombres_dataset = pd.read_csv(f'{folder_path_data}/nombres_dataset.csv')\n",
        "  df_nombres_dataset = pd.DataFrame(nombres_dataset)\n",
        "\n",
        "  if df_nombres_dataset.value_counts().sum() != 4:\n",
        "    raise Exception('Hubo cambios en la cantidad de dataset considerados')\n",
        "\n",
        "  print(\"Todo en orden, en la generación de los distintos archivos\")\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Verificación archivos')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Verificación archivos')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sección que crea el archivo txt de la descripción de las fuentes descargadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxfL8ahdP8VM",
        "outputId": "cdd1f38d-b18c-40ff-d463-1e8ad17f7e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos de datos descargados y descripción en txt creada.\n"
          ]
        }
      ],
      "source": [
        "# Creando el archivo de texto con descripción general de las fuentes de descargar y parte del proceso ETL\n",
        "\n",
        "try:\n",
        "   \n",
        "  # Verificando si la carpeta existe, si no, crearla\n",
        "  if not os.path.exists(folder_path_log):\n",
        "    os.makedirs(folder_path_log)\n",
        "\n",
        "  # Uniendo elementos de la lista de las fuentes en donde se han descargado los datos (sources_list)\n",
        "  texto_list = \"\\n\".join(sources_list)\n",
        "  texto_list_mujeres_indicador = \"\\n\".join([\"\\t- \" + elemento for elemento in serie_mujeres_indicador])\n",
        "  texto_list_mujeres_region = \"\\n\".join([\"\\t- \" + elemento for elemento in serie_mujeres_region])\n",
        "\n",
        "  date_now = datetime.now()\n",
        "\n",
        "  # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "  description = f\"\"\"\n",
        "  Proyecto: \n",
        "  Narrando una historia con datos: explorando el poder de la ciencia de datos \n",
        "\n",
        "  Análisis de la variabilidad del comportamiento delictivo\n",
        "  en relación con factores temporales y geográficos, y su correlación con el desarrollo social y urbano para la prevención del delito\n",
        "\n",
        "  Equipo participante:\n",
        "  - Miguel Ernesto Medina León\n",
        "  - Luis Andrés Burruel Durán\n",
        "  - Mario Estrada Ferreira\n",
        "\n",
        "  Este cuaderno de trabajo está destinado a la adquisición de raw data de la incidencia delictiva. Se busca obtener cuatro tablas de datos específicas:\n",
        "\n",
        "  1. Cifras de incidencia delictiva estatal, 2015 - agosto 2023\n",
        "  2. Cifras de incidencia delictiva municipal, 2015 - agosto 2023\n",
        "  3. Cifras de víctimas del fuero común, 2015 - agosto 2023\n",
        "  4. Cifras de incidencia delictiva federal, 2012 - agosto 2023\n",
        "\n",
        "  Descripción de los datos descargados:\n",
        "  - Las fuentes fueron descargadas y donde se puede encontrar información adicional en el sitio web: {incidencia_delictiva_link}\n",
        "\n",
        "  Fuentes:\n",
        "  {texto_list}\n",
        "\n",
        "  Diccionario de datos:\n",
        "\n",
        "    * Cifras de incidencia delictiva estatal, 2015 - agosto 2023\n",
        "\n",
        "      - Año: año de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Clave_Ent: clave de la entidad, según el Marco Geoestadístico Nacional (MGN) del Instituto Nacional de Geografía y Estadística (INEGI).\n",
        "      - Entidad: entidad federativa de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Bien jurídico afectado: primera clasificación de los delitos en las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Tipo de delito: segunda clasificación de los delitos.\n",
        "      - Subtipo de delito: tercera clasificación de los delitos.\n",
        "      - Modalidad: cuarta clasificación de los delitos.\n",
        "      - Enero - diciembre: mes de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "\n",
        "    * Cifras de incidencia delictiva municipal, 2015 - agosto 2023\n",
        "\n",
        "      - Año: año de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Clave_Ent: clave de la entidad, según el Marco Geoestadístico Nacional (MGN) del Instituto Nacional de Geografía y Estadística (INEGI).\n",
        "      - Entidad: entidad federativa de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Cve. Municipio: clave del municipio, según el Marco Geoestadístico Nacional (MGN) del Instituto Nacional de Geografía y Estadística (INEGI).\n",
        "      - Municipio: municipio de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Bien jurídico afectado: primera clasificación de los delitos en las averiguaciones previas y/o carpetas de investigación. \n",
        "      - Tipo de delito: segunda clasificación de los delitos.\n",
        "      - Subtipo de delito: tercera clasificación de los delitos.\n",
        "      - Modalidad: cuarta clasificación de los delitos.\n",
        "      - Enero - diciembre: mes de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "\n",
        "    * Cifras de víctimas del fuero común, 2015 - agosto 2023\n",
        "\n",
        "      - Año: año de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Clave_Ent: clave de la entidad, según el Marco Geoestadístico Nacional (MGN) del Instituto Nacional de Geografía y Estadística (INEGI).\n",
        "      - Entidad: cntidad federativa de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "      - Bien jurídico afectado: primera clasificación de los delitos en las averiguaciones previas y/o carpetas de investigación. \n",
        "      - Tipo de delito: segunda clasificación de los delitos.\n",
        "      - Subtipo de delito: tercera clasificación de los delitos.\n",
        "      - Modalidad: cuarta clasificación de los delitos.\n",
        "      - Sexo: Sexo de las víctimas: se divide en Hombre, Mujer y No identificado.\n",
        "      - Rango de edad: rangos de edades de las víctimas, clasificadas en: Adultos (18 y más), Menores de edad (0-17), No especificado y No identificado.\n",
        "      - Enero - diciembre: mes de registro de las averiguaciones previas y/o carpetas de investigación.\n",
        "\n",
        "\n",
        "    * Cifras de incidencia delictiva federal, 2012 - agosto 2023\n",
        "\n",
        "      - ANO: Año de registro de las Averiguaciones Previas y/o carpetas de investigación.\n",
        "      - INEGI: clave INEGI\n",
        "      - ENTIDAD: Entidad federativa de registro de las Averiguaciones Previas y/o carpetas de investigación.\n",
        "      - LEY: Primera clasificación de los delitos en las Averiguaciones Previas y/o carpetas de investigación. Está dividido según la ley que los regula:\n",
        "      Código Penal Federal u Otras Leyes o Códigos.\n",
        "      - CONCEPTO: Segunda clasificación de los delitos: para los delitos regulados por el Código Penal Federal se divide en \"Contra la salud\" y \"Otros delitos\",\n",
        "      para Otras Leyes y Códigos está dividida en: \"Ley General de Salud (L.G.S.)\", \"Ley Federal Contra la Delincuencia Organizada (L.F.C.D.O.)\" y \"Otras Leyes y Códigos\".\n",
        "      - TIPO: Tercera clasificación de los delitos: \"Contra la salud\" se divide en  producción, transporte, tráfico, comercio, suministro, posesión y otros; \n",
        "      \"Otros delitos\" se divide en Cometidos por servidores públicos, Contra el ambiente y la gestión ambiental, Contra la integridad corporal, Electorales, En materia de \n",
        "      derechos de autor, Falsedad, Titulo décimo tercero, Patrimoniales, Vías de comunicación y correspondencia y Otros delitos del C.P.F. para los delitos regulados por \n",
        "      Otras Leyes o Códigos la división es la siguiente:\"Ley General de Salud (L.G.S.)\" en Contra la salud en su modalidad de narcomenudeo y Otros delitos previstos en la L.G.S;\n",
        "      \"Ley Federal Contra la Delincuencia Organizada (L.F.C.D.O.)\" en Contra la salud y Otros delitos previstos en la L.F.C.D.O y \"Otras Leyes y Códigos\" en Código Fiscal De La \n",
        "      Federación (C.F.F.), Ley De La Propiedad Industrial (L.P.I.), Ley De Vías Generales De Comunicación (L.V.G.C.), Ley Federal Del Derecho De Autor (L.F.D.A.), Ley Federal De \n",
        "      Armas De Fuego Y Explosivos (L.F.A.F.E.), Ley De Migración, Leyes De Instituciones De Crédito, Inversión, Fianzas Y Seguros y Otras Leyes Especiales.\n",
        "\n",
        "  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  Datos de incidencia delictiva cometidos en contra de mujeres:\n",
        "  \n",
        "  • Por Indicador\n",
        "  {texto_list_mujeres_indicador}\n",
        "    \n",
        "  • Por Región\n",
        "  {texto_list_mujeres_region}\n",
        "\n",
        "  Estos datos han sido obtenidas de la fuente oficial: http://baesvim.sspsonora.gob.mx/Indicadores/Analisis\n",
        "\n",
        "  ¿QUÉ ES BAESVIM?\n",
        "\n",
        "  El Banco Estatal de Casos de Violencia contra las Mujeres (BAESVIM Sonora), \n",
        "  aglutina los esfuerzos coordinados de diversas dependencias en el ámbito estatal y municipal \n",
        "  con el fundamental objetivo de contar con información confiable para la elaboración de estudios y análisis estadísticos \n",
        "  que permitan la instrumentación de políticas efectivas en la atención y erradicación de la violencia contra las mujeres en Sonora.\n",
        "\n",
        "  INSTANCIAS PROVEEDORAS DE INFORMACIÓN\n",
        "  \n",
        "  El Articulo 28 de la Ley de Acceso de las Mujeres a una Vida Libre de Violencia para el Estado de Sonora, \n",
        "  establece en su fracción II: La Secretaría de Seguridad Pública tendrá a su cargo Integrar el Banco Estatal de Datos e Información sobre Casos de Violencia contra las Mujeres.\n",
        "  \n",
        "  Actualmente BAESVIM Sonora, integra información de las siguientes instancias:\n",
        "\n",
        "  • Secretaría de Salud (SS)\n",
        "  • Secretaría de Educación y Cultura (SEC)\n",
        "  • Fiscalia General de Justicia del Estado (FGJE)\n",
        "  • Supremo Tribunal de Justicia del Estado (STJE)\n",
        "  • Sistema para el Desarrollo Integral de la Familia (DIF Sonora)\n",
        "  • Sistema para el Desarrollo Integral de la Familia Hermosillo (DIF Hermosillo)\n",
        "  • Instituto Sonorense de las Mujeres (ISM)\n",
        "  • Secretaría de Desarrollo Social (SEDESON)\n",
        "  • Instituto Cajemense de la Mujer (ICM)\n",
        "  • Dirección General de Atención a la Mujer en Hermosillo (DGAM)\n",
        "  • Grupo Especializado en la Atención a la Violencia Intrafamiliar (GEAVI)\n",
        "  • Comisión Estatal de Derechos Humanos (CEDH)\n",
        "  • Instituto Nogalense de las Mujeres\n",
        "  • Secretaría de Seguridad Pública (SSP)\n",
        "\n",
        "  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  Regiones geográficas del estado de Sonora:\n",
        "\n",
        "  - Noraeste\n",
        "  - Sur\n",
        "  - Sierra Alta\n",
        "  - Sierra centro\n",
        "  - Centro norte\n",
        "  - Río Sonora\n",
        "\n",
        "  Estas regiones geográficas han sido obtenidas de la fuente oficial: https://contraloria.sonora.gob.mx/component/zoo/category/regiones.html\n",
        "\n",
        "  Coordenadas geográficas de los municipios de Sonora\n",
        "\n",
        "  Estas coordenadas geográficas representan la ubicación geoespacial de los municipios dentro del estado de Sonora y han sido recuperadas de la fuente: https://www.coordenadas.com.es/mexico/pueblos-de-sonora/26/\n",
        "\n",
        "  Fechas de descarga:\n",
        "  - El proceso de descarga de los datos se realizó el: {date_now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "  \"\"\"\n",
        "  # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "  with open(f'{folder_path_log}/fuentes_descripcion{date_now.strftime(\"%d%m%y\")}_Incidencia_Delictiva.txt', 'w', encoding='utf-8') as description_file:\n",
        "      description_file.write(description)\n",
        "\n",
        "  print(\"Archivos de datos descargados y descripción en txt creada.\")\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Creación de archivo de descripción general')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Creación de archivo de descripción general')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

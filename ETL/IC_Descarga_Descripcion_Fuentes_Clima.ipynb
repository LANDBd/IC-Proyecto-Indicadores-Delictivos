{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCyt0iMusRFt"
      },
      "source": [
        "## DESCARGA DE DATOS METEOROLÓGICOS Y DE CLIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9fBPGtp08yj",
        "outputId": "9fb16457-b5e0-4b82-9d5c-56a6c0bd9693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: openpyxl in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
            "Requirement already satisfied: requests in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wget in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\lordm\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->gdown) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in c:\\users\\lordm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalando las paqueterías necesarias.\n",
        "%pip install pandas openpyxl requests beautifulsoup4\n",
        "%pip install wget\n",
        "%pip install gdown\n",
        "%pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IEemuFTtDrC"
      },
      "source": [
        "Las siguientes librerías nos ayudaran para el desarrollo del proceso de descarga y generación del archivo txt. es necesario que este al principio para su correcto funcionamiento.\n",
        "\n",
        "Se utiliza librerías especiales como gwdown para descarga de archivos grandes, eliminando la confirmación de permiso de descarga.\n",
        "\n",
        "Se utiliza librería unicode, para poder quitar los acentos de ciertas palabras y usarlo como nombre de archivos a descargar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AHoMZUHn1HMc"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías para usarlas en el proyecto de descarga y generación del txt con la descripción de esta\n",
        "import pandas as pd\n",
        "import wget\n",
        "import gdown\n",
        "import requests\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from logging import exception\n",
        "from unidecode import unidecode\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY2yRhPNtKJt"
      },
      "source": [
        "La inicialización de ciertas variables ayudaran a preparar la información inicial de cada una de ellas, además de que puedan ser usadas en cualquier parte del código o proceso, sin en el que perjudique el ámbito o espacio donde estas estén siendo seteadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W0us0zIt1OHA"
      },
      "outputs": [],
      "source": [
        "# Inicializando variables que serán usadas más adelante\n",
        "\n",
        "incidencia_clima_link = 'https://open-meteo.com/en/docs/historical-weather-api'\n",
        "incidencia_title = ''\n",
        "incidencia_description = ''\n",
        "\n",
        "folder_path_data = '../rawdata'\n",
        "folder_path_log = '../logs/descarga/'\n",
        "folder_path_error_log = '../logs/errores/'\n",
        "csv_filepath = ''\n",
        "\n",
        "# Creando variable que contendra el listado de cada source descargado.\n",
        "sources_list = []\n",
        "\n",
        "# Creando variable que contendra el listado de cada nombre de archivo descargado y que esta siendo enviado a nuestro repositorio\n",
        "names_files_list = []\n",
        "\n",
        "texto_list = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBbh9Rk6tOo9"
      },
      "source": [
        "#### Sección donde se encuentran las funciones generales del proceso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1w_Kqimi1P3H"
      },
      "outputs": [],
      "source": [
        "def log_error_write(description, line):\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_error_log):\n",
        "        os.makedirs(folder_path_error_log)\n",
        "\n",
        "    date_now = datetime.now()\n",
        "\n",
        "    # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "    line_error = f\"\"\"{date_now.strftime('%Y-%m-%d %H:%M:%S')} {line} - {description}\"\"\"\n",
        "    # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "    with open(f'{folder_path_error_log}/ddf_err{date_now.strftime(\"%d%m%y\")}.txt', 'a', encoding=\"utf-8\") as error_file:\n",
        "        error_file.write(f\"\\n{line_error}\")\n",
        "\n",
        "def log_write(description, line):\n",
        "    # Verificando si la carpeta existe, si no, crearla\n",
        "    if not os.path.exists(folder_path_log):\n",
        "        os.makedirs(folder_path_log)\n",
        "\n",
        "    date_now = datetime.now()\n",
        "\n",
        "    # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "    line_write = f\"\"\"{date_now.strftime('%Y-%m-%d %H:%M:%S')} {line} - {description}\"\"\"\n",
        "    # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "    with open(f'{folder_path_log}/muncoord{date_now.strftime(\"%d%m%y\")}.txt', 'a', encoding=\"utf-8\") as write_file:\n",
        "        write_file.write(f\"\\n{line_write}\")\n",
        "\n",
        "\n",
        "def create_csv_from_DataFrame(df, csv_filename):\n",
        "    try:\n",
        "\n",
        "        # Construyendo la ruta completa del archivo\n",
        "        csv_filepath = os.path.join(folder_path_data, csv_filename)\n",
        "\n",
        "        # Guardando el DataFrame como un archivo CSV\n",
        "        df.to_csv(csv_filepath, index=False, encoding='utf-8')\n",
        "        print(f\"DataFrame guardado exitosamente en {csv_filepath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Imprimiendo un mensaje de error en caso de excepción\n",
        "        log_error_write(f\"Error al guardar el DataFrame como CSV: {e}\", 'create_csv_from_DataFrame')\n",
        "        print(f\"Error al guardar el DataFrame como CSV: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDEpIII46Qfd"
      },
      "source": [
        "#### Web Scraping para obtener las coordenadas geográficas de todos los municipios de Sonora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q0fkTfV6LT_",
        "outputId": "9dae6bdb-6868-4a8f-8b96-035a75775501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame guardado exitosamente en ../rawdata\\municipios_coordenadas.csv\n",
            "        municipio   latitude   longitude\n",
            "0         Aconchi  29.825040 -110.227170\n",
            "1     Agua-Prieta  30.948490 -109.274370\n",
            "2          Alamos  27.026940 -108.936590\n",
            "3           Altar  30.713610 -111.835280\n",
            "4        Arivechi  28.927990 -109.188300\n",
            "..            ...        ...         ...\n",
            "67          Rayón  29.710556 -110.570278\n",
            "68        Rosario  28.050000 -109.300000\n",
            "69      Santa Ana  30.543889 -111.121111\n",
            "70  Villa Hidalgo  30.250000 -109.333333\n",
            "71  Benito Juárez  27.100000 -109.850000\n",
            "\n",
            "[72 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Inicializando listas para almacenar los datos\n",
        "ciudades = []\n",
        "latitudes = []\n",
        "longitudes = []\n",
        "\n",
        "try:\n",
        "\n",
        "  for num in range(2):\n",
        "    url = f'https://www.coordenadas.com.es/mexico/pueblos-de-sonora/26/{num + 1}'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    pretty_soup = soup.prettify()\n",
        "\n",
        "  # Encontrando el elemento tabla desde el html obtenido\n",
        "    tabla = soup.find('table', class_='table')\n",
        "\n",
        "    # Iterarando sobre las filas de la tabla\n",
        "    for fila in tabla.find_all('tr'):\n",
        "        # buscando y encontrando las celdas de la fila\n",
        "        celdas = fila.find_all('td')\n",
        "\n",
        "        # Verificando si hay celdas (evitando encabezados de la tabla)\n",
        "        if celdas:\n",
        "            # Extrayendo el texto de la etiqueta <a> dentro de la primera celda\n",
        "            ciudad = celdas[0].find('a').text.strip()\n",
        "            # Extrayendo el texto de la segunda celda\n",
        "            coordenada = celdas[1].text.strip()\n",
        "\n",
        "            # Dividiendo las coordenadas en latitude y longitude\n",
        "            latitud, longitud = map(float, coordenada.split(','))\n",
        "\n",
        "            ciudades.append(ciudad)\n",
        "            latitudes.append(latitud)\n",
        "            longitudes.append(longitud)\n",
        "\n",
        "  coordenadas_df = pd.DataFrame({\n",
        "     'municipio': ciudades,\n",
        "     'latitude': latitudes,\n",
        "     'longitude': longitudes\n",
        "     })\n",
        "\n",
        "\n",
        "  #llenando la informacion faltante\n",
        "\n",
        "  Mmunicipios_left_df = pd.DataFrame({\n",
        "     'municipio': [\"Magdalena\", \"Mazatán\", \"Moctezuma\", \"Rayón\", \"Rosario\", \"Santa Ana\", \"Villa Hidalgo\", \"Benito Juárez\"],\n",
        "     'latitude': [30.733333, 28.933333, 29.806111, 29.710556, 28.05, 30.543889, 30.25, 27.1],\n",
        "     'longitude': [-111.05, -110.166667, -109.679444, -110.570278, -109.3, -111.121111, -109.333333,  -109.85]\n",
        "  })\n",
        "\n",
        "  coordenadas_df = pd.concat([coordenadas_df,Mmunicipios_left_df], ignore_index = True)\n",
        "\n",
        "  create_csv_from_DataFrame(coordenadas_df, f'municipios_coordenadas.csv')\n",
        "\n",
        "  # Mostrar el DataFrame resultante\n",
        "  print(coordenadas_df)\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'web scraping coordenadas')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'web scraping coordenadas')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUn6tcDTseDc"
      },
      "source": [
        "#### Descarga de datos históricos climatológicos y meteorológicos  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqEqA4vk5AcB",
        "outputId": "03f37a26-2c48-4d19-ef24-6a3f73286cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aconchi\n",
            "Agua-Prieta\n",
            "Alamos\n",
            "Altar\n",
            "Arivechi\n",
            "Arizpe\n",
            "Atil\n",
            "Bacadehuachi\n",
            "Bacanora\n",
            "Bacerac\n",
            "Bacoachi\n",
            "Bacum\n",
            "Banamichi\n",
            "Baviacora\n",
            "Bavispe\n",
            "Benjamin-Hill\n",
            "Caborca\n",
            "Cajeme\n",
            "Cananea\n",
            "Carbo\n",
            "Cucurpe\n",
            "Cumpas\n",
            "Divisaderos\n",
            "Empalme\n",
            "Etchojoa\n",
            "Fronteras\n",
            "General-Plutarco-Elias-Calles\n",
            "Granados\n",
            "Guaymas\n",
            "Hermosillo\n",
            "Huachinera\n",
            "Huasabas\n",
            "Huatabampo\n",
            "Huepac\n",
            "Imuris\n",
            "La-Colorada\n",
            "Naco\n",
            "Nacori-Chico\n",
            "Nacori-Chico - Demasiadas solicitudes. Esperando....\n",
            "Nacozari-de-Garcia\n",
            "Nacozari-de-Garcia - Demasiadas solicitudes. Esperando....\n",
            "Navojoa\n",
            "Navojoa - Demasiadas solicitudes. Esperando....\n",
            "Nogales\n",
            "Nogales - Demasiadas solicitudes. Esperando....\n",
            "Onavas\n",
            "Onavas - Demasiadas solicitudes. Esperando....\n",
            "Opodepe\n",
            "Opodepe - Demasiadas solicitudes. Esperando....\n",
            "Oquitoa\n",
            "Oquitoa - Demasiadas solicitudes. Esperando....\n",
            "Pitiquito\n",
            "Pitiquito - Demasiadas solicitudes. Esperando....\n",
            "Puerto-Penasco\n",
            "Quiriego\n",
            "Sahuaripa\n",
            "San-Felipe-de-Jesus\n",
            "San-Ignacio-Rio-Muerto\n",
            "San-Javier\n",
            "San-Luis-Rio-Colorado\n",
            "San-Miguel-de-Horcasitas\n",
            "San-Pedro-de-La-Cueva\n",
            "Santa-Cruz\n",
            "Saric\n",
            "Soyopa\n",
            "Suaqui-Grande\n",
            "Tepache\n",
            "Trincheras\n",
            "Tubutama\n",
            "Ures\n",
            "Villa-Pesqueira\n",
            "Yecora\n",
            "Yecora - Demasiadas solicitudes. Esperando....\n",
            "Magdalena\n",
            "Magdalena - Demasiadas solicitudes. Esperando....\n",
            "Mazatán\n",
            "Mazatán - Demasiadas solicitudes. Esperando....\n",
            "Moctezuma\n",
            "Moctezuma - Demasiadas solicitudes. Esperando....\n",
            "Rayón\n",
            "Rayón - Demasiadas solicitudes. Esperando....\n",
            "Rosario\n",
            "Rosario - Demasiadas solicitudes. Esperando....\n",
            "Santa Ana\n",
            "Santa Ana - Demasiadas solicitudes. Esperando....\n",
            "Villa Hidalgo\n",
            "Villa Hidalgo - Demasiadas solicitudes. Esperando....\n",
            "Benito Juárez\n",
            "Benito Juárez - Demasiadas solicitudes. Esperando....\n",
            "DataFrame guardado exitosamente en ../rawdata\\DatosClimaMunicipal.csv\n",
            "DataFrame guardado exitosamente en ../rawdata\\DatosClimaMunicipal_ignorados\n"
          ]
        }
      ],
      "source": [
        "# Calculando la fecha anterior restando un día\n",
        "date_yesterday = datetime.now() - timedelta(days=1)\n",
        "end_date_str = date_yesterday.strftime('%Y-%m-%d')\n",
        "\n",
        "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "\n",
        "wheater_df =  pd.DataFrame()\n",
        "coordenadas_ignore = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "\n",
        "    for index,row in coordenadas_df.iterrows():\n",
        "\n",
        "        print(row[\"municipio\"])\n",
        "\n",
        "        parameters = {\n",
        "            \"latitude\": row['latitude'],\n",
        "            \"longitude\": row['longitude'],\n",
        "            \"start_date\": \"2015-01-01\",\n",
        "            \"end_date\": end_date_str,\n",
        "            \"daily\": \"temperature_2m_max,temperature_2m_min,temperature_2m_mean,sunrise,sunset,precipitation_sum,rain_sum,precipitation_hours\",\n",
        "            \"timezone\": \"auto\"\n",
        "            }\n",
        "\n",
        "        # Realizando la solicitud GET a la API con los parámetros\n",
        "        response = requests.get(api_url, params=parameters)\n",
        "\n",
        "        if response.status_code == 429:\n",
        "             coordenadas_ignore = pd.concat([coordenadas_ignore, row.to_frame().transpose()], ignore_index=True)\n",
        "             print(f\"{row['municipio']} - Demasiadas solicitudes. Esperando....\")\n",
        "             time.sleep(5) # Espera 5 segundos antes de intentar nuevamente\n",
        "             continue\n",
        "\n",
        "        # Verificando si la solicitud fue exitosa (código 200)\n",
        "        if response.status_code == 200:\n",
        "            # Convirtiendo la respuesta JSON en un DataFrame de pandas\n",
        "            download_wheater_df = pd.DataFrame(response.json())\n",
        "\n",
        "            if download_wheater_df is not None:\n",
        "              # Obteniendo las claves (nombres de las series) de clima_df['daily']\n",
        "              daily_series = download_wheater_df['daily'].keys()\n",
        "\n",
        "              # Creando un nuevo DataFrame dinámico\n",
        "              wheater_municipio_df = pd.DataFrame({clave: download_wheater_df['daily'][clave] for clave in daily_series})\n",
        "\n",
        "              wheater_municipio_df['municipio'] = row['municipio']\n",
        "\n",
        "              wheater_df = pd.concat([wheater_df,wheater_municipio_df], ignore_index = True)\n",
        "\n",
        "              log_write(row['municipio'],f\"Descarga-coordenada\")\n",
        "\n",
        "        time.sleep(120) # Espera 120 segundos entre solicitudes para no superar la tasa limite de descarga\n",
        "\n",
        "        # Verificar cada 10 iteraciones\n",
        "        if (index + 1) % 10 == 0:\n",
        "             time.sleep(50)\n",
        "\n",
        "    create_csv_from_DataFrame(wheater_df, f'DatosClimaMunicipal.csv')\n",
        "    create_csv_from_DataFrame(coordenadas_ignore, f'DatosClimaMunicipal_ignorados')\n",
        "\n",
        "except Exception as e:\n",
        "        # Imprimir un mensaje de error en caso de excepción\n",
        "        log_error_write(f\"Ocurrió un error inesperado: {e}\", 'decarga_datos_wheater')\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3vHaXqkshan"
      },
      "source": [
        "#### Descarga de datos históricos climatológicos y meteorológicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJJT97pKsrxk"
      },
      "source": [
        "> (version test, con 5 llamaddos solamente para no saturar y que provoque error 429)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asmgY1asnlJQ",
        "outputId": "67d8185c-7557-4269-a7de-9e4965e59be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aconchi\n",
            "Agua-Prieta\n",
            "Alamos\n",
            "Altar\n",
            "Arivechi\n",
            "DataFrame guardado exitosamente en ../rawdata\\DatosClimaMunicipal.csv\n",
            "DataFrame guardado exitosamente en ../rawdata\\DatosClimaMunicipal_ignorados.csv\n"
          ]
        }
      ],
      "source": [
        "# Calculando la fecha anterior restando un día\n",
        "date_yesterday = datetime.now() - timedelta(days=1)\n",
        "end_date_str = date_yesterday.strftime('%Y-%m-%d')\n",
        "\n",
        "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "\n",
        "wheater_df =  pd.DataFrame()\n",
        "coordenadas_ignore = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "\n",
        "    for index,row in coordenadas_df.iterrows():\n",
        "        if index < 5:\n",
        "            print(row[\"municipio\"])\n",
        "\n",
        "            parameters = {\n",
        "                \"latitude\": row['latitude'],\n",
        "                \"longitude\": row['longitude'],\n",
        "                \"start_date\": \"2015-01-01\",\n",
        "                \"end_date\": end_date_str,\n",
        "                \"daily\": \"temperature_2m_max,temperature_2m_min,temperature_2m_mean,sunrise,sunset,precipitation_sum,rain_sum,precipitation_hours\",\n",
        "                \"timezone\": \"auto\"\n",
        "                }\n",
        "\n",
        "            # Realizando la solicitud GET a la API con los parámetros\n",
        "            response = requests.get(api_url, params=parameters)\n",
        "\n",
        "            if response.status_code == 429:\n",
        "                coordenadas_ignore = pd.concat([coordenadas_ignore, row.to_frame().transpose()], ignore_index=True)\n",
        "                print(f\"{row['municipio']} - Demasiadas solicitudes. Esperando....\")\n",
        "                time.sleep(5) # Espera 5 segundos antes de intentar nuevamente\n",
        "                continue\n",
        "\n",
        "            # Verificando si la solicitud fue exitosa (código 200)\n",
        "            if response.status_code == 200:\n",
        "                # Convirtiendo la respuesta JSON en un DataFrame de pandas\n",
        "                download_wheater_df = pd.DataFrame(response.json())\n",
        "\n",
        "                if download_wheater_df is not None:\n",
        "                    # Obteniendo las claves (nombres de las series) de clima_df['daily']\n",
        "                    daily_series = download_wheater_df['daily'].keys()\n",
        "\n",
        "                    # Creando un nuevo DataFrame dinámico\n",
        "                    wheater_municipio_df = pd.DataFrame({clave: download_wheater_df['daily'][clave] for clave in daily_series})\n",
        "\n",
        "                    wheater_municipio_df['municipio'] = row['municipio']\n",
        "\n",
        "                    wheater_df = pd.concat([wheater_df,wheater_municipio_df], ignore_index = True)\n",
        "\n",
        "                    log_write(row['municipio'],f\"Descarga-coordenada\")\n",
        "\n",
        "            time.sleep(20) # Espera 20 segundos entre solicitudes para no superar la tasa limite de descarga\n",
        "\n",
        "            # Verificar cada 10 iteraciones\n",
        "            if (index + 1) % 10 == 0:\n",
        "                time.sleep(50)\n",
        "\n",
        "    create_csv_from_DataFrame(wheater_df, f'DatosClimaMunicipal.csv')\n",
        "    create_csv_from_DataFrame(coordenadas_ignore, f'DatosClimaMunicipal_ignorados.csv')\n",
        "\n",
        "except Exception as e:\n",
        "        # Imprimir un mensaje de error en caso de excepción\n",
        "        log_error_write(f\"Ocurrió un error inesperado: {e}\", 'decarga_datos_wheater')\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOTzwHkkxmDe"
      },
      "source": [
        "#### Sección que crea el archivo txt de la descripción de las fuentes descargadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SwBh0HPWxbOh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos de datos descargados y descripción en txt creada.\n"
          ]
        }
      ],
      "source": [
        "# Creando el archivo de texto con descripción general de las fuentes de descargar y parte del proceso ETL\n",
        "\n",
        "try:\n",
        "\n",
        "  # Verificando si la carpeta existe, si no, crearla\n",
        "  if not os.path.exists(folder_path_log):\n",
        "    os.makedirs(folder_path_log)\n",
        "\n",
        "  # Uniendo elementos de la lista de las fuentes en donde se han descargado los datos (sources_list)\n",
        "  texto_list = \"\\n\".join(sources_list)\n",
        "\n",
        "  date_now = datetime.now()\n",
        "\n",
        "  # Variable que contiene el texto que tendrá el archivo txt que se generará y descargará.\n",
        "  description = f\"\"\"\n",
        "  Proyecto:\n",
        "  Narrando una historia con datos: explorando el poder de la ciencia de datos\n",
        "\n",
        "  Análisis de la variabilidad del comportamiento delictivo\n",
        "  en relación con factores temporales y geográficos, y su correlación con el desarrollo social y urbano para la prevención del delito\n",
        "\n",
        "  Equipo participante:\n",
        "  - Miguel Ernesto Medina León\n",
        "  - Luis Andrés Burruel Durán\n",
        "  - Mario Estrada Ferreira\n",
        "\n",
        "  Este cuaderno de trabajo está destinado a la adquisición de raw data de los datos climatológicos a nivel municipal. Se busca obtener una tabla de datos específicas:\n",
        "\n",
        "  1. Datos clima municipal.\n",
        "\n",
        "  Descripción de los datos descargados:\n",
        "  - Los datos utilizados en este proyecto fueron adquiridos a través de la API Historical Weather. Se encuentra disponible información adicional\n",
        "    acerca de esta API en el siguiente sitio web: https://open-meteo.com/en/docs/historical-weather-api\n",
        "\n",
        "  \n",
        "  Fuentes:\n",
        "  https://archive-api.open-meteo.com/v1/archive\n",
        "\n",
        "  Diccionario de datos:\n",
        "\n",
        "    * Datos clima municipal\n",
        "\n",
        "      - time: fecha correspondiente al día en el que se realizaron las mediciones climáticas.\n",
        "      - temperature_2m_max: temperatura máxima diaria registrada a una altura de dos metros sobre el nivel del suelo.\n",
        "      - temperature_2m_min: temperatura mínima diaria registrada a una altura de dos metros sobre el nivel del suelo.\n",
        "      - sunrise: hora diaria en la cual el Sol se eleva sobre el horizonte.\n",
        "      - sunset: hora diaria en la cual el Sol se oculta bajo el horizonte.\n",
        "      - rain_sum: cantidad acumulada de precipitación diaria.\n",
        "      - precipitation_hours: número de horas con precipitación registradas en un día específico.\n",
        "      - temperature_2m_mean: temperatura promedio diaria registrada a dos metros sobre el nivel del suelo.\n",
        "      - precipitacion_sum: suma total de la precipitación diaria, incluyendo lluvia, nieve, llovizna, entre otras formas de precipitación.\n",
        "      - municipio: municipio en el cual se llevaron a cabo las mediciones climáticas correspondientes.\n",
        "\n",
        "\n",
        "Coordenadas geográficas de los municipios de Sonora\n",
        "\n",
        "Estas coordenadas geográficas representan la ubicación geoespacial de los municipios dentro del estado de Sonora y han sido recuperadas de la fuente: https://www.coordenadas.com.es/mexico/pueblos-de-sonora/26/\n",
        "    \n",
        "\n",
        "  Fechas de descarga:\n",
        "  - El proceso de descarga de los datos se realizó el: {date_now.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "  \"\"\"\n",
        "  # Se crea el archivo a partir del texto de arriba, el cual se guardará con el nombre descriptivo más la fecha día*mes*año, para identificar la descarga por día.\n",
        "  with open(f'{folder_path_log}/fuentes_descripcion{date_now.strftime(\"%d%m%y\")}_Clima.txt', 'w', encoding='utf-8') as description_file:\n",
        "      description_file.write(description)\n",
        "\n",
        "  print(\"Archivos de datos descargados y descripción en txt creada.\")\n",
        "\n",
        "except ValueError as ve:\n",
        "  # Manejo de errores para entradas no válidas (por ejemplo, si no se ingresa un número)\n",
        "  log_error_write(f\"Error de valor: {ve}\", 'Creación de archivo de descripción general')\n",
        "  print(f\"Error de valor: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "  # Manejo de errores para cualquier otro tipo de excepción no anticipada\n",
        "  log_error_write(f\"Ocurrió un error inesperado: {e}\", 'Creación de archivo de descripción general')\n",
        "  print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
